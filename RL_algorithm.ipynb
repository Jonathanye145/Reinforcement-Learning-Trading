{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c63ab81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Walk-Forward Validation.\n",
      "\n",
      "===== FOLD: Training on 2005-2012, Testing on 2013-2014 =====\n",
      "PCA Warning: Using 4 components instead of desired 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 45/45 [00:00<00:00, 135.48it/s]\n",
      "Epoch 2: 100%|██████████| 45/45 [00:00<00:00, 154.35it/s]\n",
      "Epoch 3: 100%|██████████| 45/45 [00:00<00:00, 148.90it/s]\n",
      "Epoch 4: 100%|██████████| 45/45 [00:00<00:00, 151.89it/s]\n",
      "Epoch 5: 100%|██████████| 45/45 [00:00<00:00, 146.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Transformer Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730/730 [00:01<00:00, 550.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD: Training on 2007-2014, Testing on 2015-2016 =====\n",
      "PCA Warning: Using 4 components instead of desired 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 46/46 [00:00<00:00, 143.51it/s]\n",
      "Epoch 2: 100%|██████████| 46/46 [00:00<00:00, 149.65it/s]\n",
      "Epoch 3: 100%|██████████| 46/46 [00:00<00:00, 155.11it/s]\n",
      "Epoch 4: 100%|██████████| 46/46 [00:00<00:00, 148.43it/s]\n",
      "Epoch 5: 100%|██████████| 46/46 [00:00<00:00, 149.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Transformer Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:01<00:00, 543.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD: Training on 2009-2016, Testing on 2017-2018 =====\n",
      "PCA Warning: Using 4 components instead of desired 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 46/46 [00:00<00:00, 146.55it/s]\n",
      "Epoch 2: 100%|██████████| 46/46 [00:00<00:00, 157.75it/s]\n",
      "Epoch 3: 100%|██████████| 46/46 [00:00<00:00, 163.99it/s]\n",
      "Epoch 4: 100%|██████████| 46/46 [00:00<00:00, 157.62it/s]\n",
      "Epoch 5: 100%|██████████| 46/46 [00:00<00:00, 150.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Transformer Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 617/617 [00:01<00:00, 543.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "===== FINAL WALK-FORWARD PERFORMANCE SUMMARY =====\n",
      "==================================================\n",
      "\n",
      "--- Performance: DT ---\n",
      "Total Return: -0.00%\n",
      "Max Drawdown: -24.70%\n",
      "Sharpe Ratio: 0.06\n",
      "\n",
      "--- Performance: RSI ---\n",
      "Strategy made no trades or had no volatility.\n",
      "\n",
      "--- Performance: BBands ---\n",
      "Total Return: -64.93%\n",
      "Max Drawdown: -73.08%\n",
      "Sharpe Ratio: 0.19\n",
      "\n",
      "--- Performance: Buy & Hold ---\n",
      "Total Return: 22.52%\n",
      "Max Drawdown: -35.44%\n",
      "Sharpe Ratio: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================================================================\n",
    "# CONTROL PANEL & CONFIGURATION\n",
    "# ==============================================================================\n",
    "CONFIG = {\n",
    "    \"USE_ENSEMBLE_TRAJECTORIES\": True,\n",
    "    \"USE_WALK_FORWARD_VALIDATION\": True,\n",
    "    \"USE_RISK_MANAGEMENT_OVERLAY\": True,\n",
    "    \"USE_DYNAMIC_TARGET_RETURN\": True,\n",
    "    \"N_COMPONENTS_PCA\": 10,\n",
    "    \"WINDOW_SIZE\": 30,\n",
    "    \"MAX_DRAWDOWN_LIMIT\": 0.20,\n",
    "    \"VOLATILITY_LIMIT_ATR\": 1.5,\n",
    "    \"INITIAL_CASH\": 10000,\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# DUMMY DATA & INDICATOR CALCULATION\n",
    "# ==============================================================================\n",
    "def calculate_indicators(df):\n",
    "    \"\"\"Calculates all necessary technical indicators for strategies.\"\"\"\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['Std_Dev'] = df['Close'].rolling(window=20).std()\n",
    "    df['BB_Upper'] = df['SMA_20'] + (df['Std_Dev'] * 2)\n",
    "    df['BB_Lower'] = df['SMA_20'] - (df['Std_Dev'] * 2)\n",
    "    \n",
    "    delta = df['Close'].diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    df['ATR_14'] = (df['High'] - df['Low']).rolling(window=14).mean()\n",
    "    return df.dropna()\n",
    "\n",
    "def create_dummy_dataframe(num_rows=5000):\n",
    "    dates = pd.to_datetime(pd.date_range(start='2005-01-01', periods=num_rows))\n",
    "    base_price = 100 + np.linspace(0, 200, num_rows) + np.sin(np.arange(num_rows) / 50) * 20 + np.random.randn(num_rows) * 10\n",
    "    data = {'Date': dates, 'Ticker': 'DUMMY', 'Open': base_price + np.random.randn(num_rows) * 2}\n",
    "    data['High'] = data['Open'] + np.random.uniform(0, 5, num_rows)\n",
    "    data['Low'] = data['Open'] - np.random.uniform(0, 5, num_rows)\n",
    "    data['Close'] = (data['Open'] + data['High'] + data['Low']) / 3 + np.random.randn(num_rows)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = calculate_indicators(df)\n",
    "    return df\n",
    "\n",
    "df = create_dummy_dataframe()\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. FEATURE ENGINEERING (Robust PCA)\n",
    "# ==============================================================================\n",
    "class FeatureEngineer:\n",
    "    def __init__(self, n_components=10):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.n_components_config = n_components\n",
    "        self.pca = None\n",
    "        self.feature_cols = [col for col in ['SMA_20', 'Std_Dev', 'RSI_14', 'ATR_14'] if col in df.columns]\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        data = data.copy()\n",
    "        scaled_features = self.scaler.fit_transform(data[self.feature_cols])\n",
    "        n_samples, n_features = scaled_features.shape\n",
    "        actual_n_components = min(self.n_components_config, n_samples, n_features)\n",
    "        \n",
    "        if actual_n_components < self.n_components_config:\n",
    "            print(f\"PCA Warning: Using {actual_n_components} components instead of desired {self.n_components_config}.\")\n",
    "            \n",
    "        self.pca = PCA(n_components=actual_n_components)\n",
    "        pca_features = self.pca.fit_transform(scaled_features)\n",
    "        \n",
    "        feature_df = pd.DataFrame(pca_features, index=data.index, columns=[f'PC_{i+1}' for i in range(pca_features.shape[1])])\n",
    "        processed_df = pd.concat([data[['Date', 'Close', 'ATR_14']], feature_df], axis=1)\n",
    "        processed_df['Norm_ATR'] = data['ATR_14'] / data['ATR_14'].rolling(window=252, min_periods=1).mean()\n",
    "        return processed_df.dropna()\n",
    "\n",
    "    def transform(self, data):\n",
    "        data = data.copy()\n",
    "        scaled_features = self.scaler.transform(data[self.feature_cols])\n",
    "        pca_features = self.pca.transform(scaled_features)\n",
    "        feature_df = pd.DataFrame(pca_features, index=data.index, columns=[f'PC_{i+1}' for i in range(pca_features.shape[1])])\n",
    "        processed_df = pd.concat([data[['Date', 'Close', 'ATR_14']], feature_df], axis=1)\n",
    "        processed_df['Norm_ATR'] = data['ATR_14'] / data['ATR_14'].rolling(window=252, min_periods=1).mean()\n",
    "        return processed_df.dropna()\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. TRAJECTORY GENERATION\n",
    "# ==============================================================================\n",
    "def get_trajectories(data, window_size):\n",
    "    short_ma = data['Close'].rolling(window=10).mean(); long_ma = data['Close'].rolling(window=30).mean()\n",
    "    ma_policy_actions = np.where(short_ma > long_ma, 1, 0)\n",
    "    \n",
    "    s, a, r, t = _generate_trajectory_from_actions(data, ma_policy_actions)\n",
    "    if len(s) <= window_size: return np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    rewards_to_go = np.cumsum(r[::-1])[::-1]\n",
    "    \n",
    "    all_states, all_actions, all_rtg, all_timesteps = [], [], [], []\n",
    "    for i in range(len(s) - window_size):\n",
    "        all_states.append(s[i:i+window_size])\n",
    "        all_actions.append(a[i:i+window_size])\n",
    "        all_rtg.append(rewards_to_go[i:i+window_size])\n",
    "        all_timesteps.append(t[i:i+window_size])\n",
    "            \n",
    "    return np.array(all_states), np.array(all_actions), np.array(all_rtg), np.array(all_timesteps)\n",
    "\n",
    "def _generate_trajectory_from_actions(data, actions):\n",
    "    rewards = []\n",
    "    cash, holdings = CONFIG[\"INITIAL_CASH\"], 0\n",
    "    feature_cols = [c for c in data.columns if c.startswith('PC_')]\n",
    "    \n",
    "    for i in range(1, len(data)):\n",
    "        prev_portfolio_val = cash + holdings * data['Close'].iloc[i-1]\n",
    "        action = actions[i]; current_price = data['Close'].iloc[i]\n",
    "\n",
    "        if action == 1 and cash > current_price: holdings += cash / current_price; cash = 0\n",
    "        elif action == 0 and holdings > 0: cash += holdings * current_price; holdings = 0\n",
    "        \n",
    "        current_portfolio_val = cash + holdings * current_price\n",
    "        rewards.append(current_portfolio_val - prev_portfolio_val)\n",
    "    \n",
    "    states = data[feature_cols].values[1:]\n",
    "    return states, actions[1:], np.array(rewards), np.arange(len(states))\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. DECISION TRANSFORMER (PAPER-ACCURATE)\n",
    "# ==============================================================================\n",
    "class DecisionTransformer(nn.Module):\n",
    "    def __init__(self, state_dim, act_dim, d_model, n_head, n_layer, max_ep_len):\n",
    "        super().__init__()\n",
    "        self.state_dim, self.act_dim, self.d_model = state_dim, act_dim, d_model\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, n_head, d_model * 4, 0.1, batch_first=True), n_layer)\n",
    "        self.embed_timestep = nn.Embedding(max_ep_len, d_model)\n",
    "        self.embed_return = nn.Linear(1, d_model)\n",
    "        self.embed_state = nn.Linear(state_dim, d_model)\n",
    "        self.embed_action = nn.Embedding(act_dim, d_model)\n",
    "        self.embed_ln = nn.LayerNorm(d_model)\n",
    "        self.predict_action = nn.Sequential(nn.Linear(d_model, act_dim), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, states, actions, returns_to_go, timesteps):\n",
    "        batch_size, seq_len = states.shape[0], states.shape[1]\n",
    "        state_embeds = self.embed_state(states)\n",
    "        action_embeds = self.embed_action(actions)\n",
    "        rtg_embeds = self.embed_return(returns_to_go)\n",
    "        time_embeds = self.embed_timestep(timesteps)\n",
    "        state_embeds += time_embeds; action_embeds += time_embeds; rtg_embeds += time_embeds\n",
    "        \n",
    "        stacked_inputs = torch.stack((rtg_embeds, state_embeds, action_embeds), dim=1\n",
    "        ).permute(0, 2, 1, 3).reshape(batch_size, 3 * seq_len, self.d_model)\n",
    "        stacked_inputs = self.embed_ln(stacked_inputs)\n",
    "        \n",
    "        mask = nn.Transformer.generate_square_subsequent_mask(3 * seq_len).to(states.device)\n",
    "        transformer_out = self.transformer(stacked_inputs, mask=mask)\n",
    "        \n",
    "        state_out = transformer_out[:, 1::3]\n",
    "        action_preds = self.predict_action(state_out)\n",
    "        return action_preds\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. TRAINING & BACKTESTING\n",
    "# ==============================================================================\n",
    "def train(model, states, actions, rtg, timesteps, epochs=5, batch_size=64):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device).train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    s = torch.from_numpy(states).float()\n",
    "    a = torch.from_numpy(actions).long()\n",
    "    r = torch.from_numpy(rtg).float()\n",
    "    t = torch.from_numpy(timesteps).long()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in tqdm(range(0, len(states), batch_size), desc=f\"Epoch {epoch+1}\"):\n",
    "            s_b, a_b, r_b, t_b = s[i:i+batch_size].to(device), a[i:i+batch_size].to(device), r[i:i+batch_size].to(device), t[i:i+batch_size].to(device)\n",
    "            if s_b.shape[0] == 0: continue\n",
    "            action_preds = model(s_b, a_b, r_b.unsqueeze(-1), t_b)\n",
    "            loss = F.cross_entropy(action_preds.reshape(-1, model.act_dim), a_b.reshape(-1))\n",
    "            optimizer.zero_grad(); loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "def backtest_dt(model, data, window_size, initial_cash):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval().to(device)\n",
    "    cash, holdings = initial_cash, 0\n",
    "    portfolio_values, high_water_mark = [initial_cash], initial_cash\n",
    "    feature_cols = [c for c in data.columns if c.startswith('PC_')]\n",
    "    \n",
    "    context_states = torch.zeros(1, window_size, model.state_dim, device=device, dtype=torch.float32)\n",
    "    context_actions = torch.zeros(1, window_size, dtype=torch.long, device=device)\n",
    "    context_rtg = torch.zeros(1, window_size, 1, device=device, dtype=torch.float32)\n",
    "    context_timesteps = torch.arange(window_size, device=device).reshape(1, window_size)\n",
    "\n",
    "    print(\"Running Decision Transformer Backtest...\")\n",
    "    for i in tqdm(range(len(data))):\n",
    "        current_state = torch.from_numpy(data[feature_cols].iloc[i].values).float().reshape(1, 1, model.state_dim).to(device)\n",
    "        context_states = torch.cat([context_states[:, 1:], current_state], dim=1)\n",
    "        \n",
    "        target_return = initial_cash * 0.1\n",
    "        if CONFIG[\"USE_DYNAMIC_TARGET_RETURN\"] and 'Norm_ATR' in data.columns and data['Norm_ATR'].iloc[i] > 0:\n",
    "            target_return *= data['Norm_ATR'].iloc[i]\n",
    "        \n",
    "        rtg_update = torch.tensor([[[target_return]]], device=device, dtype=torch.float32)\n",
    "        context_rtg = torch.cat([context_rtg[:, 1:], rtg_update], dim=1)\n",
    "\n",
    "        with torch.no_grad(): action_preds = model(context_states, context_actions, context_rtg, context_timesteps)\n",
    "        proposed_action = torch.argmax(action_preds[0, -1, :]).item()\n",
    "        \n",
    "        final_action = proposed_action\n",
    "        if CONFIG[\"USE_RISK_MANAGEMENT_OVERLAY\"]:\n",
    "             current_drawdown = (high_water_mark - portfolio_values[-1]) / high_water_mark if high_water_mark > 0 else 0\n",
    "             if current_drawdown > CONFIG[\"MAX_DRAWDOWN_LIMIT\"]: final_action = 0\n",
    "             if 'Norm_ATR' in data.columns and data['Norm_ATR'].iloc[i] > CONFIG[\"VOLATILITY_LIMIT_ATR\"]: final_action = 0\n",
    "        \n",
    "        current_price = data['Close'].iloc[i]\n",
    "        if final_action == 1 and cash > current_price: holdings += cash / current_price; cash = 0\n",
    "        elif final_action == 0 and holdings > 0: cash += holdings * current_price; holdings = 0\n",
    "        \n",
    "        new_value = cash + holdings * current_price\n",
    "        portfolio_values.append(new_value); high_water_mark = max(high_water_mark, new_value)\n",
    "        context_actions = torch.cat([context_actions[:, 1:], torch.tensor([[final_action]], device=device)], dim=1)\n",
    "\n",
    "    return pd.Series(portfolio_values[1:], index=data['Date'])\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. TRADITIONAL STRATEGIES & BENCHMARKING\n",
    "# ==============================================================================\n",
    "def generate_rsi_signals(data, buy_threshold=30, sell_threshold=70):\n",
    "    signals = pd.Series(index=data.index, dtype=int)\n",
    "    signals[data['RSI_14'] < buy_threshold] = 1\n",
    "    signals[data['RSI_14'] > sell_threshold] = -1\n",
    "    signals = signals.ffill().fillna(0)\n",
    "    return signals\n",
    "\n",
    "def generate_bb_signals(data):\n",
    "    signals = pd.Series(index=data.index, dtype=int)\n",
    "    signals[data['Close'] > data['BB_Upper']] = 1\n",
    "    signals[data['Close'] < data['BB_Lower']] = -1\n",
    "    signals = signals.ffill().fillna(0)\n",
    "    return signals\n",
    "\n",
    "def backtest_traditional(data, signals, initial_cash):\n",
    "    cash = initial_cash\n",
    "    holdings = 0\n",
    "    portfolio_values = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        signal = signals.iloc[i]\n",
    "        current_price = data['Close'].iloc[i]\n",
    "        \n",
    "        if signal == 1 and holdings == 0:\n",
    "            holdings = cash / current_price; cash = 0\n",
    "        elif signal == -1 and holdings > 0:\n",
    "            cash = holdings * current_price; holdings = 0\n",
    "        \n",
    "        portfolio_values.append(cash + holdings * current_price)\n",
    "        \n",
    "    return pd.Series(portfolio_values, index=data.index)\n",
    "\n",
    "def display_performance(name, portfolio_values, benchmark_series):\n",
    "    returns = portfolio_values.pct_change().dropna()\n",
    "    if returns.empty or returns.std() == 0:\n",
    "        print(f\"\\n--- Performance: {name} ---\\nStrategy made no trades or had no volatility.\"); return {}\n",
    "    \n",
    "    final_val = portfolio_values.iloc[-1]\n",
    "    total_return = (final_val - portfolio_values.iloc[0]) / portfolio_values.iloc[0]\n",
    "    high_water_mark = portfolio_values.cummax()\n",
    "    drawdown = (portfolio_values - high_water_mark) / high_water_mark\n",
    "    max_drawdown = drawdown.min()\n",
    "    sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "    \n",
    "    print(f\"\\n--- Performance: {name} ---\")\n",
    "    print(f\"Total Return: {total_return:.2%}\")\n",
    "    print(f\"Max Drawdown: {max_drawdown:.2%}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "    \n",
    "    return {'Return': total_return, 'Max Drawdown': max_drawdown, 'Sharpe': sharpe_ratio}\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. MAIN EXECUTION LOGIC\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    engineer = FeatureEngineer(n_components=CONFIG[\"N_COMPONENTS_PCA\"])\n",
    "    \n",
    "    if not CONFIG[\"USE_WALK_FORWARD_VALIDATION\"]: pass\n",
    "    else:\n",
    "        print(\"Running Walk-Forward Validation.\")\n",
    "        df['Date'] = pd.to_datetime(df['Date']); df = df.set_index('Date')\n",
    "        unique_years = df.index.year.unique(); train_window_yrs, test_window_yrs = 8, 2\n",
    "        \n",
    "        all_results = []\n",
    "\n",
    "        for i in range(train_window_yrs, len(unique_years), test_window_yrs):\n",
    "            train_start_year, train_end_year = unique_years[i - train_window_yrs], unique_years[i - 1]\n",
    "            test_start_year = unique_years[i]\n",
    "            test_end_year = unique_years[min(i + test_window_yrs - 1, len(unique_years)-1)]\n",
    "            print(f\"\\n===== FOLD: Training on {train_start_year}-{train_end_year}, Testing on {test_start_year}-{test_end_year} =====\")\n",
    "            \n",
    "            train_df, test_df = df[str(train_start_year):str(train_end_year)], df[str(test_start_year):str(test_end_year)]\n",
    "            processed_train = engineer.fit_transform(train_df.reset_index()); processed_test = engineer.transform(test_df.reset_index())\n",
    "            \n",
    "            states, actions, rtg, timesteps = get_trajectories(processed_train, CONFIG[\"WINDOW_SIZE\"])\n",
    "            if states.shape[0] < 1: print(\"Not enough data for DT. Skipping fold.\"); continue\n",
    "            \n",
    "            state_dim = states.shape[2]\n",
    "            model = DecisionTransformer(state_dim, 2, d_model=128, n_head=4, n_layer=3, max_ep_len=10000)\n",
    "            model = train(model, states, actions, rtg, timesteps, epochs=5)\n",
    "            dt_portfolio = backtest_dt(model, processed_test, CONFIG[\"WINDOW_SIZE\"], CONFIG[\"INITIAL_CASH\"])\n",
    "            \n",
    "            rsi_signals = generate_rsi_signals(test_df)\n",
    "            rsi_portfolio = backtest_traditional(test_df, rsi_signals, CONFIG[\"INITIAL_CASH\"])\n",
    "            \n",
    "            bb_signals = generate_bb_signals(test_df)\n",
    "            bb_portfolio = backtest_traditional(test_df, bb_signals, CONFIG[\"INITIAL_CASH\"])\n",
    "\n",
    "            all_results.append({'DT': dt_portfolio, 'RSI': rsi_portfolio, 'BBands': bb_portfolio, 'Benchmark': test_df['Close']})\n",
    "\n",
    "        # --- Final Performance Aggregation and Comparison ---\n",
    "        print(\"\\n\\n\" + \"=\"*50); print(\"===== FINAL WALK-FORWARD PERFORMANCE SUMMARY =====\"); print(\"=\"*50)\n",
    "\n",
    "        final_portfolios = {}\n",
    "        for key in ['DT', 'RSI', 'BBands', 'Benchmark']:\n",
    "            full_series = pd.concat([res[key] for res in all_results])\n",
    "            if key == 'Benchmark':\n",
    "                final_portfolios['Buy & Hold'] = full_series * (CONFIG[\"INITIAL_CASH\"] / full_series.iloc[0])\n",
    "            else:\n",
    "                returns = full_series.pct_change().fillna(0)\n",
    "                equity_curve = [CONFIG[\"INITIAL_CASH\"]]\n",
    "                for r in returns.iloc[1:]: equity_curve.append(equity_curve[-1] * (1 + r))\n",
    "                \n",
    "                # --- FIX: Use the full index to match the length of the equity curve ---\n",
    "                final_portfolios[key] = pd.Series(equity_curve, index=full_series.index)\n",
    "\n",
    "        benchmark_series = final_portfolios['Buy & Hold']\n",
    "        for name, portfolio in final_portfolios.items():\n",
    "            if not portfolio.empty:\n",
    "                display_performance(name, portfolio, benchmark_series)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
