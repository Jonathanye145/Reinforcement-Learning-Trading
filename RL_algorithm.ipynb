{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63ab81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Walk-Forward Validation.\n",
      "\n",
      "===== FOLD: Training on 2000-2007, Testing on 2008-2009 =====\n",
      "PCA Warning: Using 4 components instead of desired 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 43/43 [00:00<00:00, 95.95it/s] \n",
      "Epoch 2: 100%|██████████| 43/43 [00:00<00:00, 167.37it/s]\n",
      "Epoch 3: 100%|██████████| 43/43 [00:00<00:00, 155.06it/s]\n",
      "Epoch 4: 100%|██████████| 43/43 [00:00<00:00, 148.24it/s]\n",
      "Epoch 5: 100%|██████████| 43/43 [00:00<00:00, 146.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Transformer Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:01<00:00, 560.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD: Training on 2002-2009, Testing on 2010-2011 =====\n",
      "PCA Warning: Using 4 components instead of desired 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 46/46 [00:00<00:00, 150.21it/s]\n",
      "Epoch 2: 100%|██████████| 46/46 [00:00<00:00, 148.47it/s]\n",
      "Epoch 3: 100%|██████████| 46/46 [00:00<00:00, 158.72it/s]\n",
      "Epoch 4: 100%|██████████| 46/46 [00:00<00:00, 147.71it/s]\n",
      "Epoch 5: 100%|██████████| 46/46 [00:00<00:00, 150.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Transformer Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730/730 [00:01<00:00, 555.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD: Training on 2004-2011, Testing on 2012-2013 =====\n",
      "PCA Warning: Using 4 components instead of desired 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 46/46 [00:00<00:00, 146.88it/s]\n",
      "Epoch 2: 100%|██████████| 46/46 [00:00<00:00, 147.17it/s]\n",
      "Epoch 3: 100%|██████████| 46/46 [00:00<00:00, 149.16it/s]\n",
      "Epoch 4: 100%|██████████| 46/46 [00:00<00:00, 150.67it/s]\n",
      "Epoch 5: 100%|██████████| 46/46 [00:00<00:00, 153.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Transformer Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:01<00:00, 543.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD: Training on 2006-2013, Testing on 2014-2015 =====\n",
      "PCA Warning: Using 4 components instead of desired 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 46/46 [00:00<00:00, 148.30it/s]\n",
      "Epoch 2: 100%|██████████| 46/46 [00:00<00:00, 149.85it/s]\n",
      "Epoch 3: 100%|██████████| 46/46 [00:00<00:00, 149.55it/s]\n",
      "Epoch 4: 100%|██████████| 46/46 [00:00<00:00, 148.25it/s]\n",
      "Epoch 5: 100%|██████████| 46/46 [00:00<00:00, 150.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Transformer Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730/730 [00:01<00:00, 540.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD: Training on 2008-2015, Testing on 2016-2017 =====\n",
      "PCA Warning: Using 4 components instead of desired 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 46/46 [00:00<00:00, 145.37it/s]\n",
      "Epoch 2: 100%|██████████| 46/46 [00:00<00:00, 158.60it/s]\n",
      "Epoch 3: 100%|██████████| 46/46 [00:00<00:00, 165.37it/s]\n",
      "Epoch 4: 100%|██████████| 46/46 [00:00<00:00, 157.74it/s]\n",
      "Epoch 5: 100%|██████████| 46/46 [00:00<00:00, 146.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Transformer Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:01<00:00, 541.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD: Training on 2010-2017, Testing on 2018-2019 =====\n",
      "PCA Warning: Using 4 components instead of desired 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 46/46 [00:00<00:00, 154.39it/s]\n",
      "Epoch 2: 100%|██████████| 46/46 [00:00<00:00, 155.46it/s]\n",
      "Epoch 3: 100%|██████████| 46/46 [00:00<00:00, 147.37it/s]\n",
      "Epoch 4: 100%|██████████| 46/46 [00:00<00:00, 148.88it/s]\n",
      "Epoch 5: 100%|██████████| 46/46 [00:00<00:00, 151.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Decision Transformer Backtest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 425/425 [00:00<00:00, 565.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "===== FINAL WALK-FORWARD PERFORMANCE SUMMARY =====\n",
      "==================================================\n",
      "\n",
      "--- Performance: DT ---\n",
      "Total Return: -11.14%\n",
      "Max Drawdown: -34.72%\n",
      "Sharpe Ratio: 0.08\n",
      "\n",
      "--- Performance: MA_Cross ---\n",
      "Total Return: 16.31%\n",
      "Max Drawdown: -29.98%\n",
      "Sharpe Ratio: 0.28\n",
      "\n",
      "--- Performance: RSI ---\n",
      "Total Return: 0.00%\n",
      "Max Drawdown: -20.35%\n",
      "Sharpe Ratio: 0.11\n",
      "\n",
      "--- Performance: BBands ---\n",
      "Total Return: -40.25%\n",
      "Max Drawdown: -57.86%\n",
      "Sharpe Ratio: 0.26\n",
      "\n",
      "--- Performance: MACD ---\n",
      "Total Return: -94.40%\n",
      "Max Drawdown: -99.97%\n",
      "Sharpe Ratio: 0.43\n",
      "\n",
      "--- Performance: Donchian ---\n",
      "Total Return: 0.00%\n",
      "Max Drawdown: -36.05%\n",
      "Sharpe Ratio: 0.20\n",
      "\n",
      "--- Performance: Buy & Hold ---\n",
      "Total Return: 70.92%\n",
      "Max Drawdown: -33.09%\n",
      "Sharpe Ratio: 0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================================================================\n",
    "# CONTROL PANEL & CONFIGURATION\n",
    "# ==============================================================================\n",
    "CONFIG = {\n",
    "    \"USE_WALK_FORWARD_VALIDATION\": True,\n",
    "    \"USE_RISK_MANAGEMENT_OVERLAY\": True,\n",
    "    \"USE_DYNAMIC_TARGET_RETURN\": True,\n",
    "    \"N_COMPONENTS_PCA\": 10,\n",
    "    \"WINDOW_SIZE\": 30, # Context length K for the Transformer\n",
    "    \"MAX_DRAWDOWN_LIMIT\": 0.20,\n",
    "    \"VOLATILITY_LIMIT_ATR\": 1.5,\n",
    "    \"INITIAL_CASH\": 10000,\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# DATA PREPARATION & INDICATOR CALCULATION\n",
    "# ==============================================================================\n",
    "def calculate_indicators(df):\n",
    "    \"\"\"Calculates all necessary technical indicators for all strategies.\"\"\"\n",
    "    # Bollinger Bands\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['Std_Dev'] = df['Close'].rolling(window=20).std()\n",
    "    df['BB_Upper'] = df['SMA_20'] + (df['Std_Dev'] * 2)\n",
    "    df['BB_Lower'] = df['SMA_20'] - (df['Std_Dev'] * 2)\n",
    "    # RSI\n",
    "    delta = df['Close'].diff(1)\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "    # ATR\n",
    "    df['ATR_14'] = (df['High'] - df['Low']).rolling(window=14).mean()\n",
    "    # Golden/Death Cross\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['SMA_200'] = df['Close'].rolling(window=200).mean()\n",
    "    # MACD\n",
    "    ema_12 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    ema_26 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = ema_12 - ema_26\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    # Donchian Channels\n",
    "    df['Donchian_Upper'] = df['High'].rolling(window=20).max()\n",
    "    df['Donchian_Lower'] = df['Low'].rolling(window=20).min()\n",
    "    return df.dropna()\n",
    "\n",
    "def create_dummy_dataframe(num_rows=7000): # Increased rows for long-term MAs\n",
    "    dates = pd.to_datetime(pd.date_range(start='2000-01-01', periods=num_rows))\n",
    "    base_price = 100 + np.linspace(0, 300, num_rows) + np.sin(np.arange(num_rows) / 50) * 20 + np.random.randn(num_rows) * 10\n",
    "    data = {'Date': dates, 'Ticker': 'DUMMY', 'Open': base_price + np.random.randn(num_rows) * 2}\n",
    "    data['High'] = data['Open'] + np.random.uniform(0, 5, num_rows)\n",
    "    data['Low'] = data['Open'] - np.random.uniform(0, 5, num_rows)\n",
    "    data['Close'] = (data['Open'] + data['High'] + data['Low']) / 3 + np.random.randn(num_rows)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = calculate_indicators(df)\n",
    "    return df\n",
    "\n",
    "df = create_dummy_dataframe()\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. FEATURE ENGINEERING (Robust PCA)\n",
    "# ==============================================================================\n",
    "class FeatureEngineer:\n",
    "    def __init__(self, n_components=10):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.n_components_config = n_components\n",
    "        self.pca = None\n",
    "        self.feature_cols = [col for col in ['SMA_20', 'RSI_14', 'ATR_14', 'MACD'] if col in df.columns]\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        data = data.copy()\n",
    "        scaled_features = self.scaler.fit_transform(data[self.feature_cols])\n",
    "        n_samples, n_features = scaled_features.shape\n",
    "        actual_n_components = min(self.n_components_config, n_samples, n_features)\n",
    "        \n",
    "        if actual_n_components < self.n_components_config:\n",
    "            print(f\"PCA Warning: Using {actual_n_components} components instead of desired {self.n_components_config}.\")\n",
    "            \n",
    "        self.pca = PCA(n_components=actual_n_components)\n",
    "        pca_features = self.pca.fit_transform(scaled_features)\n",
    "        \n",
    "        feature_df = pd.DataFrame(pca_features, index=data.index, columns=[f'PC_{i+1}' for i in range(pca_features.shape[1])])\n",
    "        processed_df = pd.concat([data[['Date', 'Close', 'ATR_14']], feature_df], axis=1)\n",
    "        processed_df['Norm_ATR'] = data['ATR_14'] / data['ATR_14'].rolling(window=252, min_periods=1).mean()\n",
    "        return processed_df.dropna()\n",
    "\n",
    "    def transform(self, data):\n",
    "        data = data.copy()\n",
    "        scaled_features = self.scaler.transform(data[self.feature_cols])\n",
    "        pca_features = self.pca.transform(scaled_features)\n",
    "        feature_df = pd.DataFrame(pca_features, index=data.index, columns=[f'PC_{i+1}' for i in range(pca_features.shape[1])])\n",
    "        processed_df = pd.concat([data[['Date', 'Close', 'ATR_14']], feature_df], axis=1)\n",
    "        processed_df['Norm_ATR'] = data['ATR_14'] / data['ATR_14'].rolling(window=252, min_periods=1).mean()\n",
    "        return processed_df.dropna()\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. TRAJECTORY GENERATION for Decision Transformer\n",
    "# ==============================================================================\n",
    "def get_trajectories(data, window_size):\n",
    "    short_ma = data['Close'].rolling(window=10).mean(); long_ma = data['Close'].rolling(window=30).mean()\n",
    "    ma_policy_actions = np.where(short_ma > long_ma, 1, 0) # 1: Buy, 0: Sell\n",
    "    \n",
    "    s, a, r, t = _generate_trajectory_from_actions(data, ma_policy_actions)\n",
    "    if len(s) <= window_size: return np.array([]), np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    rewards_to_go = np.cumsum(r[::-1])[::-1]\n",
    "    all_states, all_actions, all_rtg, all_timesteps = [], [], [], []\n",
    "    for i in range(len(s) - window_size):\n",
    "        all_states.append(s[i:i+window_size])\n",
    "        all_actions.append(a[i:i+window_size])\n",
    "        all_rtg.append(rewards_to_go[i:i+window_size])\n",
    "        all_timesteps.append(t[i:i+window_size])\n",
    "    return np.array(all_states), np.array(all_actions), np.array(all_rtg), np.array(all_timesteps)\n",
    "\n",
    "def _generate_trajectory_from_actions(data, actions):\n",
    "    rewards = []\n",
    "    cash, holdings = CONFIG[\"INITIAL_CASH\"], 0\n",
    "    feature_cols = [c for c in data.columns if c.startswith('PC_')]\n",
    "    for i in range(1, len(data)):\n",
    "        prev_portfolio_val = cash + holdings * data['Close'].iloc[i-1]\n",
    "        action = actions[i]; current_price = data['Close'].iloc[i]\n",
    "        if action == 1 and cash > current_price: holdings += cash / current_price; cash = 0\n",
    "        elif action == 0 and holdings > 0: cash += holdings * current_price; holdings = 0\n",
    "        rewards.append((cash + holdings * current_price) - prev_portfolio_val)\n",
    "    return data[feature_cols].values[1:], actions[1:], np.array(rewards), np.arange(len(actions)-1)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. DECISION TRANSFORMER MODEL\n",
    "# ==============================================================================\n",
    "class DecisionTransformer(nn.Module):\n",
    "    def __init__(self, state_dim, act_dim, d_model, n_head, n_layer, max_ep_len):\n",
    "        super().__init__()\n",
    "        self.state_dim, self.act_dim, self.d_model = state_dim, act_dim, d_model\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model, n_head, d_model * 4, 0.1, batch_first=True), n_layer)\n",
    "        self.embed_timestep = nn.Embedding(max_ep_len, d_model)\n",
    "        self.embed_return = nn.Linear(1, d_model)\n",
    "        self.embed_state = nn.Linear(state_dim, d_model)\n",
    "        self.embed_action = nn.Embedding(act_dim, d_model)\n",
    "        self.embed_ln = nn.LayerNorm(d_model)\n",
    "        self.predict_action = nn.Sequential(nn.Linear(d_model, act_dim), nn.Softmax(dim=-1))\n",
    "\n",
    "    def forward(self, states, actions, returns_to_go, timesteps):\n",
    "        batch_size, seq_len = states.shape[0], states.shape[1]\n",
    "        state_embeds = self.embed_state(states)\n",
    "        action_embeds = self.embed_action(actions)\n",
    "        rtg_embeds = self.embed_return(returns_to_go)\n",
    "        time_embeds = self.embed_timestep(timesteps)\n",
    "        state_embeds += time_embeds; action_embeds += time_embeds; rtg_embeds += time_embeds\n",
    "        stacked_inputs = torch.stack((rtg_embeds, state_embeds, action_embeds), dim=1\n",
    "        ).permute(0, 2, 1, 3).reshape(batch_size, 3 * seq_len, self.d_model)\n",
    "        stacked_inputs = self.embed_ln(stacked_inputs)\n",
    "        mask = nn.Transformer.generate_square_subsequent_mask(3 * seq_len).to(states.device)\n",
    "        transformer_out = self.transformer(stacked_inputs, mask=mask)\n",
    "        state_out = transformer_out[:, 1::3]\n",
    "        return self.predict_action(state_out)\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. TRAINING & BACKTESTING LOGIC\n",
    "# ==============================================================================\n",
    "def train(model, states, actions, rtg, timesteps, epochs=5, batch_size=64):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device).train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    s, a, r, t = torch.from_numpy(states).float(), torch.from_numpy(actions).long(), torch.from_numpy(rtg).float(), torch.from_numpy(timesteps).long()\n",
    "    for epoch in range(epochs):\n",
    "        for i in tqdm(range(0, len(states), batch_size), desc=f\"Epoch {epoch+1}\"):\n",
    "            s_b, a_b, r_b, t_b = s[i:i+batch_size].to(device), a[i:i+batch_size].to(device), r[i:i+batch_size].to(device), t[i:i+batch_size].to(device)\n",
    "            if s_b.shape[0] == 0: continue\n",
    "            action_preds = model(s_b, a_b, r_b.unsqueeze(-1), t_b)\n",
    "            loss = F.cross_entropy(action_preds.reshape(-1, model.act_dim), a_b.reshape(-1))\n",
    "            optimizer.zero_grad(); loss.backward(); torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0); optimizer.step()\n",
    "    return model\n",
    "\n",
    "def backtest_dt(model, data, window_size, initial_cash):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); model.eval().to(device)\n",
    "    cash, holdings = initial_cash, 0\n",
    "    portfolio_values, high_water_mark = [initial_cash], initial_cash\n",
    "    feature_cols = [c for c in data.columns if c.startswith('PC_')]\n",
    "    context_states = torch.zeros(1, window_size, model.state_dim, device=device, dtype=torch.float32)\n",
    "    context_actions = torch.zeros(1, window_size, dtype=torch.long, device=device)\n",
    "    context_rtg = torch.zeros(1, window_size, 1, device=device, dtype=torch.float32)\n",
    "    context_timesteps = torch.arange(window_size, device=device).reshape(1, window_size)\n",
    "    print(\"Running Decision Transformer Backtest...\")\n",
    "    for i in tqdm(range(len(data))):\n",
    "        current_state = torch.from_numpy(data[feature_cols].iloc[i].values).float().reshape(1, 1, model.state_dim).to(device)\n",
    "        context_states = torch.cat([context_states[:, 1:], current_state], dim=1)\n",
    "        target_return = initial_cash * 0.1\n",
    "        if CONFIG[\"USE_DYNAMIC_TARGET_RETURN\"] and 'Norm_ATR' in data.columns and data['Norm_ATR'].iloc[i] > 0:\n",
    "            target_return *= data['Norm_ATR'].iloc[i]\n",
    "        rtg_update = torch.tensor([[[target_return]]], device=device, dtype=torch.float32)\n",
    "        context_rtg = torch.cat([context_rtg[:, 1:], rtg_update], dim=1)\n",
    "        with torch.no_grad(): action_preds = model(context_states, context_actions, context_rtg, context_timesteps)\n",
    "        proposed_action = torch.argmax(action_preds[0, -1, :]).item()\n",
    "        final_action = proposed_action\n",
    "        if CONFIG[\"USE_RISK_MANAGEMENT_OVERLAY\"]:\n",
    "             current_drawdown = (high_water_mark - portfolio_values[-1]) / high_water_mark if high_water_mark > 0 else 0\n",
    "             if current_drawdown > CONFIG[\"MAX_DRAWDOWN_LIMIT\"]: final_action = 0\n",
    "             if 'Norm_ATR' in data.columns and data['Norm_ATR'].iloc[i] > CONFIG[\"VOLATILITY_LIMIT_ATR\"]: final_action = 0\n",
    "        current_price = data['Close'].iloc[i]\n",
    "        if final_action == 1 and cash > current_price: holdings += cash / current_price; cash = 0\n",
    "        elif final_action == 0 and holdings > 0: cash += holdings * current_price; holdings = 0\n",
    "        new_value = cash + holdings * current_price\n",
    "        portfolio_values.append(new_value); high_water_mark = max(high_water_mark, new_value)\n",
    "        context_actions = torch.cat([context_actions[:, 1:], torch.tensor([[final_action]], device=device)], dim=1)\n",
    "    return pd.Series(portfolio_values[1:], index=data['Date'])\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. TRADITIONAL STRATEGIES & BENCHMARKING\n",
    "# ==============================================================================\n",
    "def generate_ma_cross_signals(data):\n",
    "    signals = pd.Series(index=data.index, dtype=int)\n",
    "    signals[data['SMA_50'] > data['SMA_200']] = 1\n",
    "    signals[data['SMA_50'] < data['SMA_200']] = -1\n",
    "    return signals.ffill().fillna(0)\n",
    "\n",
    "def generate_rsi_signals(data, buy_threshold=30, sell_threshold=70):\n",
    "    signals = pd.Series(index=data.index, dtype=int)\n",
    "    signals[data['RSI_14'] < buy_threshold] = 1\n",
    "    signals[data['RSI_14'] > sell_threshold] = -1\n",
    "    return signals.ffill().fillna(0)\n",
    "\n",
    "def generate_bb_signals(data):\n",
    "    signals = pd.Series(index=data.index, dtype=int)\n",
    "    signals[data['Close'] > data['BB_Upper']] = 1\n",
    "    signals[data['Close'] < data['BB_Lower']] = -1\n",
    "    return signals.ffill().fillna(0)\n",
    "\n",
    "def generate_macd_signals(data):\n",
    "    signals = pd.Series(index=data.index, dtype=int)\n",
    "    signals[data['MACD'] > data['MACD_Signal']] = 1\n",
    "    signals[data['MACD'] < data['MACD_Signal']] = -1\n",
    "    return signals.ffill().fillna(0)\n",
    "\n",
    "def generate_donchian_signals(data):\n",
    "    signals = pd.Series(index=data.index, dtype=int)\n",
    "    signals[data['Close'] >= data['Donchian_Upper']] = 1\n",
    "    signals[data['Close'] <= data['Donchian_Lower']] = -1\n",
    "    return signals.ffill().fillna(0)\n",
    "\n",
    "def backtest_traditional(data, signals, initial_cash):\n",
    "    cash, holdings = initial_cash, 0; portfolio_values = []\n",
    "    for i in range(len(data)):\n",
    "        signal = signals.iloc[i]; current_price = data['Close'].iloc[i]\n",
    "        if signal == 1 and holdings == 0: holdings = cash / current_price; cash = 0\n",
    "        elif signal == -1 and holdings > 0: cash = holdings * current_price; holdings = 0\n",
    "        portfolio_values.append(cash + holdings * current_price)\n",
    "    return pd.Series(portfolio_values, index=data.index)\n",
    "\n",
    "def display_performance(name, portfolio_values):\n",
    "    returns = portfolio_values.pct_change().dropna()\n",
    "    if returns.empty or returns.std() == 0:\n",
    "        print(f\"\\n--- Performance: {name} ---\\nStrategy made no trades or had no volatility.\"); return\n",
    "    final_val = portfolio_values.iloc[-1]\n",
    "    total_return = (final_val - portfolio_values.iloc[0]) / portfolio_values.iloc[0]\n",
    "    high_water_mark = portfolio_values.cummax()\n",
    "    drawdown = (portfolio_values - high_water_mark) / high_water_mark\n",
    "    max_drawdown = drawdown.min()\n",
    "    sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "    print(f\"\\n--- Performance: {name} ---\")\n",
    "    print(f\"Total Return: {total_return:.2%}\")\n",
    "    print(f\"Max Drawdown: {max_drawdown:.2%}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 6. MAIN EXECUTION LOGIC\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    engineer = FeatureEngineer(n_components=CONFIG[\"N_COMPONENTS_PCA\"])\n",
    "    \n",
    "    if not CONFIG[\"USE_WALK_FORWARD_VALIDATION\"]: pass # Simplified logic removed for clarity\n",
    "    else:\n",
    "        print(\"Running Walk-Forward Validation.\")\n",
    "        df['Date'] = pd.to_datetime(df['Date']); df = df.set_index('Date')\n",
    "        unique_years = df.index.year.unique(); train_window_yrs, test_window_yrs = 8, 2\n",
    "        all_results = []\n",
    "\n",
    "        for i in range(train_window_yrs, len(unique_years), test_window_yrs):\n",
    "            train_start_year, train_end_year = unique_years[i - train_window_yrs], unique_years[i - 1]\n",
    "            test_start_year = unique_years[i]\n",
    "            test_end_year = unique_years[min(i + test_window_yrs - 1, len(unique_years)-1)]\n",
    "            print(f\"\\n===== FOLD: Training on {train_start_year}-{train_end_year}, Testing on {test_start_year}-{test_end_year} =====\")\n",
    "            \n",
    "            train_df, test_df = df[str(train_start_year):str(train_end_year)], df[str(test_start_year):str(test_end_year)]\n",
    "            processed_train = engineer.fit_transform(train_df.reset_index()); processed_test = engineer.transform(test_df.reset_index())\n",
    "            \n",
    "            # Decision Transformer\n",
    "            states, actions, rtg, timesteps = get_trajectories(processed_train, CONFIG[\"WINDOW_SIZE\"])\n",
    "            if states.shape[0] < 1: print(\"Not enough data for DT. Skipping fold.\"); continue\n",
    "            state_dim = states.shape[2]\n",
    "            model = DecisionTransformer(state_dim, 2, d_model=128, n_head=4, n_layer=3, max_ep_len=10000)\n",
    "            model = train(model, states, actions, rtg, timesteps, epochs=5)\n",
    "            dt_portfolio = backtest_dt(model, processed_test, CONFIG[\"WINDOW_SIZE\"], CONFIG[\"INITIAL_CASH\"])\n",
    "            \n",
    "            # Traditional Strategies\n",
    "            all_results.append({\n",
    "                'DT': dt_portfolio,\n",
    "                'MA_Cross': backtest_traditional(test_df, generate_ma_cross_signals(test_df), CONFIG[\"INITIAL_CASH\"]),\n",
    "                'RSI': backtest_traditional(test_df, generate_rsi_signals(test_df), CONFIG[\"INITIAL_CASH\"]),\n",
    "                'BBands': backtest_traditional(test_df, generate_bb_signals(test_df), CONFIG[\"INITIAL_CASH\"]),\n",
    "                'MACD': backtest_traditional(test_df, generate_macd_signals(test_df), CONFIG[\"INITIAL_CASH\"]),\n",
    "                'Donchian': backtest_traditional(test_df, generate_donchian_signals(test_df), CONFIG[\"INITIAL_CASH\"]),\n",
    "                'Benchmark': test_df['Close']\n",
    "            })\n",
    "\n",
    "        # --- Final Performance Aggregation and Comparison ---\n",
    "        print(\"\\n\\n\" + \"=\"*50); print(\"===== FINAL WALK-FORWARD PERFORMANCE SUMMARY =====\"); print(\"=\"*50)\n",
    "        final_portfolios = {}\n",
    "        strategy_keys = ['DT', 'MA_Cross', 'RSI', 'BBands', 'MACD', 'Donchian', 'Benchmark']\n",
    "        for key in strategy_keys:\n",
    "            full_series = pd.concat([res[key] for res in all_results if key in res and not res[key].empty])\n",
    "            if full_series.empty: continue\n",
    "            if key == 'Benchmark':\n",
    "                final_portfolios['Buy & Hold'] = full_series * (CONFIG[\"INITIAL_CASH\"] / full_series.iloc[0])\n",
    "            else:\n",
    "                returns = full_series.pct_change().fillna(0)\n",
    "                equity_curve = [CONFIG[\"INITIAL_CASH\"]]\n",
    "                for r in returns.iloc[1:]: equity_curve.append(equity_curve[-1] * (1 + r))\n",
    "                final_portfolios[key] = pd.Series(equity_curve, index=full_series.index)\n",
    "        \n",
    "        for name, portfolio in final_portfolios.items():\n",
    "            if not portfolio.empty: display_performance(name, portfolio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
